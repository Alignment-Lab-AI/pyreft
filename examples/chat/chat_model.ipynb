{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515fcf7a-c011-4a5f-9f78-b58feffaeb26",
   "metadata": {},
   "source": [
    "### Loading base LM and ReFT model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222060d4-bb6e-4edc-8119-86a4f7d85b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d90a03ce3e48788498d1848584df26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea191918c5d4f5aa3e0c0aef761a9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers\n",
    "from pyreft import (\n",
    "    ReftModel,\n",
    "    get_intervention_locations\n",
    ")\n",
    "\n",
    "prompt_no_input_template = \"\"\"Below is an instruction that \\\n",
    "describes a task. Write a response that appropriately \\\n",
    "completes the request.\n",
    "\n",
    "### Instruction:\n",
    "%s\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name_or_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "reft_model_name_or_path = \"zhengxuanzenwu/Loreft1k-Llama-2-7b-hf\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, model_max_length=2048, padding_side=\"right\", use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=device)\n",
    "reft_model = ReftModel.load(\n",
    "    \"zhengxuanzenwu/Loreft1k-Llama-2-7b-hf\", model, from_huggingface_hub=True)\n",
    "reft_model.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5eb8d-95d6-4a53-a3dd-0575e0ee0efd",
   "metadata": {},
   "source": [
    "### Inference with intervention locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a45798a-ae5f-41ce-8cc1-9fca794a49bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': False} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Tell me about the NLP Group at Stanford University.\n",
      "\n",
      "### Response:\n",
      "The Natural Language Processing (NLP) group at Stanford University is a research and teaching group focused on developing algorithms and systems for understanding human language. The group was founded in 1983 by John R. Pierce, who served as its first director until his retirement in 2004. Today, the group is led by Professor Christopher Manning, who has been the director since 2005.\n",
      "\n",
      "The NLP group's research focuses on a wide range of topics related to natural language processing, including machine translation, text classification, sentiment analysis, question answering, and more. The group also works closely with other departments at Stanford, such as Computer Science, Linguistics, and Psychology, to explore new directions in natural language processing.\n",
      "\n",
      "In addition to conducting cutting-edge research, the NLP group also offers several courses on natural language processing and artificial intelligence. These courses are open to both undergraduate and graduate students, and they provide a comprehensive introduction to the field of natural language processing. The group also hosts regular workshops and seminars, where leading experts in the field present their latest research findings.\n",
      "\n",
      "Overall, the NLP Group is a vital part of the Stanford community, providing a wealth of knowledge and expertise in the field of natural languages processing. Its research and teaching activities have helped to advance the field significantly, and it continues to play a key role in shaping the future of natural language processing and AI.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Tell me about the NLP Group at Stanford University.\"\n",
    "\n",
    "# tokenize and prepare the input\n",
    "prompt = prompt_no_input_template % instruction\n",
    "prompt = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "intervention_locations = torch.tensor([get_intervention_locations(\n",
    "    last_position=prompt[\"input_ids\"].shape[-1], positions=\"f5+l5\",\n",
    "    num_interventions=len(reft_model.interventions))]).permute(1, 0, 2).tolist()\n",
    "\n",
    "# generate\n",
    "_, reft_response = reft_model.generate(\n",
    "    prompt, \n",
    "    unit_locations={\"sources->base\": (None, intervention_locations)},\n",
    "    intervene_on_prompt=True, max_new_tokens=512, do_sample=False, \n",
    "    no_repeat_ngram_size=5, repetition_penalty=1.1,\n",
    "    eos_token_id=tokenizer.eos_token_id, early_stopping=True\n",
    ")\n",
    "print(tokenizer.decode(reft_response[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b069a40-299f-412a-8071-3900539ea1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
