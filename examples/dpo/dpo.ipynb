{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "def get_imdb(\n",
    "        split : str, sanity_check : bool = False, silent : bool = False, cache_dir : Optional[str] = None,\n",
    "        seed : int = 42\n",
    "    ) -> Dataset:\n",
    "    \"\"\"Load the IMDb dataset from Hugging Face and convert it to the necessary format.\n",
    "\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"imdb\", split=split, cache_dir=cache_dir).shuffle(seed=seed)\n",
    "    if sanity_check:\n",
    "        dataset = dataset.select(range(min(len(dataset), 1000)))\n",
    "    \n",
    "    # create pairs of negative and positive examples\n",
    "    neg_dataset = dataset.filter(lambda x: x[\"label\"] == 0, batched=False)\n",
    "    pos_dataset = dataset.filter(lambda x: x[\"label\"] == 1, batched=False)\n",
    "\n",
    "    length = min(len(neg_dataset), len(pos_dataset))\n",
    "\n",
    "    return Dataset.from_dict({\n",
    "        \"prompt\": [\"Movie review:\"] * length,\n",
    "        \"chosen\": pos_dataset[\"text\"][:length],\n",
    "        \"rejected\": neg_dataset[\"text\"][:length]\n",
    "    })\n",
    "\n",
    "dataset = get_imdb(\"train\", sanity_check=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable intervention params: 98,368 || trainable model params: 0\n",
      "model params: 124,439,808 || trainable%: 0.0790486594129107\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from pyreft import (\n",
    "    get_reft_model,\n",
    "    ReftConfig,\n",
    "    LoreftIntervention\n",
    ")\n",
    "\n",
    "# loading huggingface model\n",
    "model_name_or_path = \"gpt2\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "# wrap the model with rank-1 constant reft\n",
    "reft_config = ReftConfig(representations=[{\n",
    "    \"component\": f\"transformer.h[{i}].output\", # string access to the model component\n",
    "    # \"intervention\": ConsreftIntervention(\n",
    "    #     embed_dim=model.config.hidden_size, low_rank_dimension=1\n",
    "    # )\n",
    "    \"intervention\": LoreftIntervention(\n",
    "        embed_dim=model.config.hidden_size, low_rank_dimension=64\n",
    "    )\n",
    "} for i in [10]])\n",
    "reft_model = get_reft_model(model, reft_config)\n",
    "reft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\envs\\pyvene\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9bdaeddd17416982865145634f1d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3454e58b3014984994c8681e354d8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\Anaconda3\\envs\\pyvene\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0822225a99e0456785825f48a67e3a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5586, 'grad_norm': 4.250195503234863, 'learning_rate': 6.6666666666666675e-06, 'rewards/chosen': 0.10009765625, 'rewards/rejected': -0.2001953125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.30078125, 'logps/rejected': -760.0, 'logps/chosen': -868.0, 'logits/rejected': -107.5, 'logits/chosen': -108.5, 'epoch': 0.01}\n",
      "{'loss': 0.6309, 'grad_norm': 4.609270095825195, 'learning_rate': 6.666666666666667e-05, 'rewards/chosen': -0.1640625, 'rewards/rejected': -0.39453125, 'rewards/accuracies': 0.5555555820465088, 'rewards/margins': 0.23046875, 'logps/rejected': -764.0, 'logps/chosen': -756.0, 'logits/rejected': -108.0, 'logits/chosen': -108.0, 'epoch': 0.08}\n",
      "{'loss': 0.7527, 'grad_norm': 15.571920394897461, 'learning_rate': 0.00013333333333333334, 'rewards/chosen': -0.87109375, 'rewards/rejected': -1.0234375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.150390625, 'logps/rejected': -744.0, 'logps/chosen': -756.0, 'logits/rejected': -107.5, 'logits/chosen': -104.0, 'epoch': 0.16}\n",
      "{'loss': 0.54, 'grad_norm': 7.9175190925598145, 'learning_rate': 0.0002, 'rewards/chosen': -1.0625, 'rewards/rejected': -1.7109375, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.65234375, 'logps/rejected': -812.0, 'logps/chosen': -796.0, 'logits/rejected': -106.0, 'logits/chosen': -101.0, 'epoch': 0.25}\n",
      "{'loss': 0.6813, 'grad_norm': 20.605712890625, 'learning_rate': 0.0002666666666666667, 'rewards/chosen': -2.671875, 'rewards/rejected': -3.40625, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.73046875, 'logps/rejected': -776.0, 'logps/chosen': -716.0, 'logits/rejected': -102.5, 'logits/chosen': -101.0, 'epoch': 0.33}\n",
      "{'loss': 0.5316, 'grad_norm': 7.495781898498535, 'learning_rate': 0.0003333333333333333, 'rewards/chosen': -0.95703125, 'rewards/rejected': -1.796875, 'rewards/accuracies': 0.625, 'rewards/margins': 0.83984375, 'logps/rejected': -792.0, 'logps/chosen': -708.0, 'logits/rejected': -106.0, 'logits/chosen': -105.0, 'epoch': 0.41}\n",
      "{'loss': 0.4526, 'grad_norm': 5.331171035766602, 'learning_rate': 0.0004, 'rewards/chosen': -2.46875, 'rewards/rejected': -4.0625, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.59375, 'logps/rejected': -776.0, 'logps/chosen': -760.0, 'logits/rejected': -104.0, 'logits/chosen': -104.0, 'epoch': 0.49}\n",
      "{'loss': 0.505, 'grad_norm': 15.814889907836914, 'learning_rate': 0.00046666666666666666, 'rewards/chosen': -2.40625, 'rewards/rejected': -3.859375, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.4453125, 'logps/rejected': -744.0, 'logps/chosen': -688.0, 'logits/rejected': -97.5, 'logits/chosen': -96.0, 'epoch': 0.57}\n",
      "{'loss': 0.9642, 'grad_norm': 8.193463325500488, 'learning_rate': 0.0005333333333333334, 'rewards/chosen': -9.9375, 'rewards/rejected': -11.5625, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 1.640625, 'logps/rejected': -836.0, 'logps/chosen': -844.0, 'logits/rejected': -74.0, 'logits/chosen': -76.0, 'epoch': 0.66}\n",
      "{'loss': 0.388, 'grad_norm': 17.41219711303711, 'learning_rate': 0.0006, 'rewards/chosen': -2.03125, 'rewards/rejected': -3.59375, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.5703125, 'logps/rejected': -812.0, 'logps/chosen': -784.0, 'logits/rejected': -114.0, 'logits/chosen': -110.5, 'epoch': 0.74}\n",
      "{'loss': 0.6592, 'grad_norm': 15.31499195098877, 'learning_rate': 0.0006666666666666666, 'rewards/chosen': -3.5625, 'rewards/rejected': -4.8125, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 1.25, 'logps/rejected': -776.0, 'logps/chosen': -764.0, 'logits/rejected': -105.0, 'logits/chosen': -105.5, 'epoch': 0.82}\n",
      "{'loss': 0.6621, 'grad_norm': 10.309388160705566, 'learning_rate': 0.0007333333333333333, 'rewards/chosen': -0.81640625, 'rewards/rejected': -1.21875, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.40234375, 'logps/rejected': -776.0, 'logps/chosen': -756.0, 'logits/rejected': -107.5, 'logits/chosen': -105.5, 'epoch': 0.9}\n",
      "{'loss': 0.5697, 'grad_norm': 6.563197612762451, 'learning_rate': 0.0008, 'rewards/chosen': -3.25, 'rewards/rejected': -4.8125, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5703125, 'logps/rejected': -788.0, 'logps/chosen': -768.0, 'logits/rejected': -97.5, 'logits/chosen': -98.0, 'epoch': 0.98}\n",
      "{'loss': 1.0734, 'grad_norm': 28.001569747924805, 'learning_rate': 0.0008666666666666667, 'rewards/chosen': -8.1875, 'rewards/rejected': -9.8125, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 1.6171875, 'logps/rejected': -840.0, 'logps/chosen': -768.0, 'logits/rejected': -98.0, 'logits/chosen': -98.0, 'epoch': 1.07}\n",
      "{'loss': 0.8603, 'grad_norm': 8.958163261413574, 'learning_rate': 0.0009333333333333333, 'rewards/chosen': -5.375, 'rewards/rejected': -6.96875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.59375, 'logps/rejected': -840.0, 'logps/chosen': -732.0, 'logits/rejected': -100.5, 'logits/chosen': -98.0, 'epoch': 1.15}\n",
      "{'loss': 0.6429, 'grad_norm': 37.96388244628906, 'learning_rate': 0.001, 'rewards/chosen': -4.5, 'rewards/rejected': -6.25, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 1.75, 'logps/rejected': -800.0, 'logps/chosen': -764.0, 'logits/rejected': -107.0, 'logits/chosen': -107.0, 'epoch': 1.23}\n",
      "{'loss': 0.5622, 'grad_norm': 5.794233798980713, 'learning_rate': 0.0008936170212765957, 'rewards/chosen': -3.734375, 'rewards/rejected': -5.8125, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 2.09375, 'logps/rejected': -880.0, 'logps/chosen': -788.0, 'logits/rejected': -94.0, 'logits/chosen': -96.0, 'epoch': 1.31}\n",
      "{'loss': 0.5867, 'grad_norm': 60.73556137084961, 'learning_rate': 0.0007872340425531915, 'rewards/chosen': -1.703125, 'rewards/rejected': -2.40625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.69921875, 'logps/rejected': -792.0, 'logps/chosen': -700.0, 'logits/rejected': -109.0, 'logits/chosen': -107.0, 'epoch': 1.39}\n",
      "{'loss': 0.3671, 'grad_norm': 32.92662811279297, 'learning_rate': 0.0006808510638297873, 'rewards/chosen': -14.125, 'rewards/rejected': -22.0, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.90625, 'logps/rejected': -992.0, 'logps/chosen': -828.0, 'logits/rejected': -93.0, 'logits/chosen': -100.5, 'epoch': 1.48}\n",
      "{'loss': 1.3201, 'grad_norm': 1.1376736164093018, 'learning_rate': 0.0005744680851063831, 'rewards/chosen': -7.28125, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 1.171875, 'logps/rejected': -780.0, 'logps/chosen': -856.0, 'logits/rejected': -99.0, 'logits/chosen': -100.0, 'epoch': 1.56}\n",
      "{'loss': 0.7926, 'grad_norm': 2.002307415008545, 'learning_rate': 0.00046808510638297874, 'rewards/chosen': -0.328125, 'rewards/rejected': -0.177734375, 'rewards/accuracies': 0.25, 'rewards/margins': -0.150390625, 'logps/rejected': -784.0, 'logps/chosen': -748.0, 'logits/rejected': -110.0, 'logits/chosen': -108.0, 'epoch': 1.64}\n",
      "{'loss': 0.7688, 'grad_norm': 2.594295024871826, 'learning_rate': 0.0003617021276595745, 'rewards/chosen': -0.388671875, 'rewards/rejected': -0.322265625, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -0.0654296875, 'logps/rejected': -716.0, 'logps/chosen': -752.0, 'logits/rejected': -108.5, 'logits/chosen': -107.0, 'epoch': 1.72}\n",
      "{'loss': 0.6924, 'grad_norm': 1.6651722192764282, 'learning_rate': 0.0002553191489361702, 'rewards/chosen': 0.1298828125, 'rewards/rejected': 0.05517578125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.0751953125, 'logps/rejected': -696.0, 'logps/chosen': -792.0, 'logits/rejected': -107.5, 'logits/chosen': -106.5, 'epoch': 1.8}\n",
      "{'loss': 0.7822, 'grad_norm': 1.3475725650787354, 'learning_rate': 0.00014893617021276596, 'rewards/chosen': 0.125, 'rewards/rejected': 0.25, 'rewards/accuracies': 0.25, 'rewards/margins': -0.1259765625, 'logps/rejected': -696.0, 'logps/chosen': -752.0, 'logits/rejected': -109.5, 'logits/chosen': -106.0, 'epoch': 1.89}\n",
      "{'loss': 0.7676, 'grad_norm': 1.3103325366973877, 'learning_rate': 4.2553191489361704e-05, 'rewards/chosen': 0.1552734375, 'rewards/rejected': 0.263671875, 'rewards/accuracies': 0.25, 'rewards/margins': -0.107421875, 'logps/rejected': -784.0, 'logps/chosen': -724.0, 'logits/rejected': -110.5, 'logits/chosen': -106.5, 'epoch': 1.97}\n",
      "{'train_runtime': 82.0398, 'train_samples_per_second': 11.897, 'train_steps_per_second': 2.974, 'train_loss': 0.6915137376941618, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=244, training_loss=0.6915137376941618, metrics={'train_runtime': 82.0398, 'train_samples_per_second': 11.897, 'train_steps_per_second': 2.974, 'train_loss': 0.6915137376941618, 'epoch': 2.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from dpo import DPOReftTrainer\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-3,\n",
    "    # max_steps=500,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=10,\n",
    "    eval_steps=100,\n",
    "    output_dir=\"pv_dpo_example\",\n",
    "    # optim=\"rmsprop\",\n",
    "    warmup_steps=150,\n",
    "    report_to='none', # \"wandb\",\n",
    "    logging_first_step=True\n",
    ")\n",
    "\n",
    "beta = 0.1\n",
    "max_length = 256\n",
    "max_prompt_length = 8\n",
    "generate_during_eval = False\n",
    "\n",
    "trainer = DPOReftTrainer(\n",
    "    reft_model,\n",
    "    reft_model,\n",
    "    args=training_args,\n",
    "    beta=beta,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    max_target_length=max_length,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    generate_during_eval=generate_during_eval,\n",
    "    peft_config=None,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvene",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
